# NVIDIA NIM을 사용하여 RAG 구축
마케팅 콘텐츠 생성용 LLM을 사용하는 앱 빌드

### 1. 개발 전 선수 사항 ###

1-1 전체 개발 절차  

    *	대형 언어 모델을 효율적으로 실행할 수 있는 GPU 서버 설정
    * Llama 2 또는 Mistral과 같은 기본 LLM 선택 및 배포
    * Triton 또는 vLLM과 같은 모델 서빙 시스템을 설정하여 추론 요청 처리
    * 마케팅 매개변수(브랜드 음성, 타겟 청중, 콘텐츠 유형)를 포함한 사용자 요청을 수락하는 API 레이어 구축
    * 마케팅 요구사항을 효과적인 LLM 프롬프트로 변환하는 프롬프트 엔지니어링 시스템 생성
    * 다수의 동시 사용자를 처리하기 위한 로드 밸런서 추가
    * 모델 성능, 지연 시간 및 오류를 추적하기 위한 모니터링 구현
    * 변동하는 부하를 처리하며 시스템 충돌을 방지하기 위한 자동 스케일링 설정

### 2. NVIDIA NIM 특징 ###

    * 생성형 AI 모델을 손쉽고 확장 가능하게 배포하는 데 필요한 기능을 제공
    * 클라우드, 데이터센터, 온프레미스 환경 어디에서나 NVIDIA GPU에서 AI 모델을 실행
    * 잘 알려진 LLM 과 이들을 대규모로 실행하는 데 필요한 API를 하나의 패키지로 제공
    * 추론 엔진, 인증, 모니터링 등을 위한 데이터 관리 도구가 포함
    * 이러한 모든 기능은 로컬에 배포하거나 컨테이너화하여 Kubernetes 클러스터에 배포함

### 3. 모델 컨테이너 실행 절차 ###

    * 컨테이너가 실행 중인 하드웨어를 감지함. 이때 모델과 호환되는 하드웨어를 확인해야 함.
    * 모델과 어셋 데이터의 캐시를 마운트함. 
    * 최적화된 모델 파일을 다운로드함. 
    * 모델 파일을 로드하고 서비스를 시작함.

### 4. NVIDIA NeMo Framework

    * 생성형 AI 모델을 어디에서나 구축, 맞춤화 및 배포할 수 있는 종단 간 클라우드 네이티브 프레임워크
    * 음성, 언어, 비전 등 다양한 도메인에서 최첨단 모델을 생성할 수 있음. 
    * 텍스트 임베딩 생성 및 효율적 검색 지원하는 NeMo Retriever Text Embedding NIM 연결

    
